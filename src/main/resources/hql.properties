hql_job_parameters = \
  set hive.exec.dynamic.partition=true;\
  set hive.exec.dynamic.partition.mode=nonstrict;\
  set mapreduce.input.fileinputformat.split.minsize=2073741824;\
  set mapreduce.input.fileinputformat.split.maxsize=4073741824;\
  set hive.exec.reducers.bytes.per.reducer=1000000000;\
  set mapreduce.reduce.memory.mb=2500;\
  set mapreduce.job.maps=1200;\
  set hive.exec.reducers.max=300;\
  set hive.groupby.skewindata=true;\
  set hive.map.aggr=true;

hql_udf_jars = \
  add jar /usr/lib/hive/auxlib.new/common-udf-1.0-SNAPSHOT.jar;\
  add jar /usr/lib/hive/auxlib/cube2ETL-1.1-SNAPSHOT.jar;\
  add jar /usr/lib/hive/auxlib/Udfs.MetaTable.jar;

hql_udf_funs = \
  create temporary function getInfoFromIp as 'com.hunantv.bigdata.common.udf.IpSeekerUDF';\
  create temporary function getOSFromUa as 'com.hunantv.timger.FetchOsFromUa';\
  create temporary function getBrowserFromUa as 'com.hunantv.timger.FetchBrowserFromUa';

database_name = bigdata_dw
database_name_temp = bigdata_dw_temp

data_root_path = /data/test

pcp = 1.1.0
pcc = 1.1.1
pcc_mini = 1.1.2
mobile = 2.0.0
m = 4
llott = 4.0.0
llott_time_shift = 4.0.0

